# 2.2 感知机学习策略

#### 2.2.1 数据集的线性可分性

**定义-2.2（数据集的线性可分性）**

给定一个数据集 $$T = \{(x_1, y_1), (x_2, y_2), \dots, (x_n, y_n)\}$$，其中 ****$$x_i \in \mathcal{X} = R^n, y_i \in \mathcal{Y} = \{+1, -1\}, i = 1, 2, \dots, n$$。如果存在超平面 $$S$$ 能够将数据集的正实例和负实例完全正确地划分到平面的两侧，则称数据集 $$T$$ 为线性可分数据集（linearly separable data set）；否则为线性不可分。

#### **2.2.2 感知**机**的学习策略**

感知机学习的目标是求得一个能够将训练集正实例点和负实例点完全正确分开的分离超平面。

在输入空间 $$R^n$$ 中任一点 $$x_0$$ 到超平面 $$S$$ 的距离有 $$d = \frac{1}{||w||} | w \cdot x_0 + b|$$ ，其中 $$||w||$$ 为 $$L_2$$ 范式；而对于误分类的数据，有 $$-y_i(w\cdot x_i + b) > 0$$，设误分类点集合为 $$M$$ ，则总误差为 $$-\frac{1}{||w||} \sum_{x_i \in M} y_i(w\cdot x_i + b)$$，其中 $$\sum_{x_i \in M} y_i (w \cdot x_i + b)$$ 为感知机学习的损失函数。

感知机学习的损失函数定义为：

$$
L(w, b) = - \sum_{x_i \in M} y_i (w \cdot x_i) \geq 0
$$



