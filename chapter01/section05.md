# 1.5 正则化与交叉验证

#### 1.5.1 正则化

模型选择的典型方法是正则化（regularization），它是结构风险最小化策略的实现，是在经验风险上加一个正则化项（regularizer）或罚项（penalty term）。

正则化的目的是选择经验风险与模型复杂度同时较小的模型。

#### 1.5.2 交叉验证

将数据集切分成三部分：训练集（training set），验证集（validation set）和测试集（test set）。

* 简单交叉验证：
  * 将数据随机分为两部分（训练集和测试集）
  * 在训练集的条件下训练模型
  * 在测试集上评价各个模型的测试误差
* S折交叉验证（S-fold cross validation）：
  * 随机地将数据切分为 $$S$$ 个互不相交的子集
  * 利用 $$S-1$$ 个子集数据训练模型
  * 重复 $$S$$ 次
  * 最后以 $$S$$ 次评测中选取平均测试误差最小的模型
* 留一交叉验证（leave-one-out cross validation）：S折交叉验证的特殊情况，令 $$S=N$$ ，其中 $$N$$ 为数据集中样本的个数，在数据缺乏的情况下使用。



