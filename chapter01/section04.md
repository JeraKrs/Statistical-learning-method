# 1.4 模型评估与模型选择

#### 1.4.1 训练误差与测试误差

训练误差（training error）与测试误差（test error），学习过程中的损失函数未必是评估时使用的损失函数，但两者一致比较理想。一般让测试误差小的方法具有更好的预测能力。

训练误差的大小，对判断给定的问题是不是一个容易学习的问题是有意义的；测试误差小的方法具有更好的预测能力，是更有效的方法。

**泛化能力（generalization ability）**指学习方法对未知数据的预测能力。

#### 1.4.2 过拟合与模型选择

当假设空间含有不同复杂度（例如不同参数个数）的模型时，就要面临模型选择（model selection）。

过拟合（over-fitting）：学习时选择的模型所包含的参数过多，以致于出现模型对已知数据预测得很好，但对未知数据预测得很差。

当模型的复杂度增大时，训练误差会逐渐减小并趋向于0；而测试误差会先减小，达到最小值后又增大。当选择的模型复杂度过大时，过拟合现在就会发生。

