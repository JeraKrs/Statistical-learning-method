# 5.5 CART算法

分类与回归树模型（classification and regression tree，CART）可以进行分类，也可以进行回归。

CART算法：

* 决策树生成：基于训练数据集生成决策树
* 决策树剪枝：用验证数据对已生成的树进行剪枝并选择最优子树

#### 5.5.1 CART生成

递归地构建二叉决策树的过程：对回归树用平方误差最小化准则；对分类树用基尼指数（Gini index）最小化准则。

**算法5-5（最小二乘回归树生成算法）**

输入：训练数据集 $$D$$ 

输出：回归树 $$f(x)$$ 

1. 选择最优切分变量 $$j$$ 和切分点 $$s$$ ，求解 $$\underset{j, s}{min}[ \underset{c_1}{min} \sum_{x_i \in R_1(j, s)}(y_i - c_1)^2 + \underset{c_2}{min}\sum_{x_i \in R_2(j, s)}(y_i - c_2)^2]$$ 
2. 用选定的对 $$(j, s)$$ 划分区域并决定相应输出值： $$R_1(j, s) = \{x | x^{(j)} \leq s \}, R_2(j, s) = \{ x | x^{(j)} > s\}, \hat{c}_m = \frac{1}{N_m}\sum_{x_i \in R_m(j, s)}y_i$$ 
3. 继续对两个子区域进行步\(1\)~\(2\)，直到满足条件为止
4. 将输入空间划分成 $$M$$ 个区域 $$R_1, R_2, \dots, R_M$$ ，生成决策树

**定义5-4（基尼指数）**

在分类问题中，假设有 $$K$$ 个类，样本点属于第 $$k$$ 类的概率为 $$p_k$$ ，则概率分布的基尼指数定义为

$$
Gini(p) = \sum^{K}_{k=1}p_k(1-p_k) = 1 - \sum^{K}_{k=1}p_k^2
$$

对给定的样本集 $$D$$ 有基尼指数 $$Gini(D) = 1 - \sum^{K}_{k=1}(\frac{|C_k|}{|D|})^2$$ ，如果样本集根据特征 $$A$$ 是否取某一可能值 $$a$$ 被分割成 $$D_1, D_2$$ 两部分，则有 $$Gini(D, A) = \frac{|D_1|}{|D|}Gini(D_1) + \frac{|D_2|}{|D|}Gini(D_2)$$ 。

**算法5-6（CART生成算法）**

输入：训练数据集 $$D$$ ，停止计算的条件

输出：CART决策树

1. 对数据集 $$D$$ 计算所有可能的特征集 $$A$$ 的所有可能取值对应下的基尼指数
2. 在所有可能的切分点下，选择基尼指数最小的特征以及取值作为最优特征和最优切分点
3. 对两个子结点递归地执行步\(1\)~\(2\)，直至满足条件
4. 生成CART树

#### 5.5.2 CART剪枝

剪枝，形成一个子树序列：计算子树的损失函数 $$C_{\alpha}(T) = C(T) + \alpha|T|$$ 

* 当 $$\alpha$$ 越大时，算法倾向于 $$|T|$$ 越小的树
* 当 $$\alpha$$ 越小时，算法倾向于 $$|T|$$ 越大的树
* 当 $$\alpha = 0$$ 时， $$T_{\alpha} = T$$ 
* 当 $$\alpha = \infty$$ 时， $$T_{\alpha}$$ 为单一结点

对于结点 $$t$$ ，剪枝后整体损失函数减少程度为 $$g(t) = \frac{C(t) - C(T_t)}{|T_t| - 1}$$ 。

在 $$T_0$$ 中减去 $$g(t)$$ 最小的 $$T_t$$ ，得到 $$T_1$$ ，同时令 $$\alpha_i = g(t)$$ ，其中 $$T_1$$ 为区间 $$[\alpha_1, \alpha_2)$$ 的最优子树

选取最优子树 $$T_{\alpha}$$ ：交叉效验法

**算法5-7（CART剪枝算法）**

输入：CART算法生成的决策树 $$T_0$$ 

输出：最优决策树 $$T_{\alpha}$$ 

1. 设 $$k=0, T=T_0$$ 
2. 设 $$\alpha = \infty$$ 
3. 自下而上地对各内部结点 $$t$$ 计算 $$C(T_t), |T_t|, g(t) = \frac{C(t) - C(T_t)}{|T_t| - 1}, \alpha = min(\alpha, g(t))$$ 
4. 自上而下地访问内部结点 $$t$$ ，如果有 $$g(t) = \alpha$$ ，进行剪枝，并对结点 $$t$$ 以多数表决的方式获得类标记，得到树 $$T$$ 
5. 设 $$k = k + 1, \alpha_k = \alpha, T_k = T$$ 
6. 如果 $$T$$ 不是由根结点构成的树，回到步骤\(4\)
7. 采用交叉验证法在子树序列 $$T_0, T_1, \dots, T_n$$ 中选取最优子树 $$T_{\alpha}$$ 



